Here's the enhanced version of your bakeoff script with all the requested features:

```python
import json
import os
import time
import pandas as pd
import evaluate
import boto3
from botocore.exceptions import ClientError
from datetime import datetime
from tqdm import tqdm
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict

# --- Configuration ---
# The four models to be tested head-to-head.
# The script will automatically skip any that can't be accessed.
MODELS_TO_TEST = {
    "Nova Pro": "amazon.nova-pro-v1:0",
    "Nova Micro": "amazon.nova-micro-v1:0",
    "Nova Lite": "amazon.nova-lite-v1:0",
    "Titan Text Premier": "amazon.titan-text-premier-v1:0"
}

# Approximate cost per 1K tokens (you should verify these with AWS pricing)
MODEL_COSTS = {
    "amazon.nova-pro-v1:0": {"input": 0.0008, "output": 0.0032},
    "amazon.nova-micro-v1:0": {"input": 0.000075, "output": 0.0003},
    "amazon.nova-lite-v1:0": {"input": 0.00006, "output": 0.00024},
    "amazon.titan-text-premier-v1:0": {"input": 0.0005, "output": 0.0015}
}

LANGUAGES = {
    "Arabic": "ar",
    "Chinese (Simplified)": "zh",
    "Russian": "ru",
    "Japanese": "ja",
    "Hindi": "hi",
    "German": "de",
    "French": "fr",
    "Spanish": "es",
    "Filipino (Tagalog)": "tl"
}

TEST_PHRASES = [
    "Climate change is a long-term shift in global weather patterns and temperatures.",
    "What are the most effective strategies for mitigating the impacts of climate change in coastal communities?",
    "Renewable energy sources, such as solar and wind power, are crucial for reducing carbon emissions.",
    "The agricultural sector must adapt to changing climate conditions to ensure food security.",
    "International cooperation is essential for addressing the global challenge of climate change."
]

# In a real-world scenario, these would be high-quality, human-generated translations.
REFERENCE_TRANSLATIONS = {
    "ar": [
        "ØªØºÙŠØ± Ø§Ù„Ù…Ù†Ø§Ø® Ù‡Ùˆ ØªØ­ÙˆÙ„ Ø·ÙˆÙŠÙ„ Ø§Ù„Ø£Ù…Ø¯ ÙÙŠ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø·Ù‚Ø³ ÙˆØ¯Ø±Ø¬Ø§Øª Ø§Ù„Ø­Ø±Ø§Ø±Ø© Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ©.",
        "Ù…Ø§ Ù‡ÙŠ Ø£ÙƒØ«Ø± Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª ÙØ¹Ø§Ù„ÙŠØ© Ù„Ù„ØªØ®ÙÙŠÙ Ù…Ù† Ø¢Ø«Ø§Ø± ØªØºÙŠØ± Ø§Ù„Ù…Ù†Ø§Ø® ÙÙŠ Ø§Ù„Ù…Ø¬ØªÙ…Ø¹Ø§Øª Ø§Ù„Ø³Ø§Ø­Ù„ÙŠØ©ØŸ",
        "ØªØ¹Ø¯ Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø·Ø§Ù‚Ø© Ø§Ù„Ù…ØªØ¬Ø¯Ø¯Ø©ØŒ Ù…Ø«Ù„ Ø§Ù„Ø·Ø§Ù‚Ø© Ø§Ù„Ø´Ù…Ø³ÙŠØ© ÙˆØ·Ø§Ù‚Ø© Ø§Ù„Ø±ÙŠØ§Ø­ØŒ Ø­Ø§Ø³Ù…Ø© Ù„Ø®ÙØ¶ Ø§Ù†Ø¨Ø¹Ø§Ø«Ø§Øª Ø§Ù„ÙƒØ±Ø¨ÙˆÙ†.",
        "ÙŠØ¬Ø¨ Ø¹Ù„Ù‰ Ø§Ù„Ù‚Ø·Ø§Ø¹ Ø§Ù„Ø²Ø±Ø§Ø¹ÙŠ Ø§Ù„ØªÙƒÙŠÙ Ù…Ø¹ Ø§Ù„Ø¸Ø±ÙˆÙ Ø§Ù„Ù…Ù†Ø§Ø®ÙŠØ© Ø§Ù„Ù…ØªØºÙŠØ±Ø© Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø£Ù…Ù† Ø§Ù„ØºØ°Ø§Ø¦ÙŠ.",
        "Ø§Ù„ØªØ¹Ø§ÙˆÙ† Ø§Ù„Ø¯ÙˆÙ„ÙŠ Ø¶Ø±ÙˆØ±ÙŠ Ù„Ù…ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ­Ø¯ÙŠ Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠ Ø§Ù„Ù…ØªÙ…Ø«Ù„ ÙÙŠ ØªØºÙŠØ± Ø§Ù„Ù…Ù†Ø§Ø®."
    ],
    "zh": [
        "æ°”å€™å˜åŒ–æ˜¯å…¨çƒå¤©æ°”æ¨¡å¼å’Œæ¸©åº¦çš„é•¿æœŸè½¬å˜ã€‚",
        "åœ¨æ²¿æµ·ç¤¾åŒºï¼Œå‡ç¼“æ°”å€™å˜åŒ–å½±å“æœ€æœ‰æ•ˆçš„ç­–ç•¥æ˜¯ä»€ä¹ˆï¼Ÿ",
        "å¤ªé˜³èƒ½å’Œé£èƒ½ç­‰å¯å†ç”Ÿèƒ½æºå¯¹äºå‡å°‘ç¢³æ’æ”¾è‡³å…³é‡è¦ã€‚",
        "å†œä¸šéƒ¨é—¨å¿…é¡»é€‚åº”ä¸æ–­å˜åŒ–çš„æ°”å€™æ¡ä»¶ï¼Œä»¥ç¡®ä¿ç²®é£Ÿå®‰å…¨ã€‚",
        "å›½é™…åˆä½œå¯¹äºåº”å¯¹æ°”å€™å˜åŒ–çš„å…¨çƒæŒ‘æˆ˜è‡³å…³é‡è¦ã€‚"
    ],
    "ru": [
        "Ğ˜Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ ĞºĞ»Ğ¸Ğ¼Ğ°Ñ‚Ğ° - ÑÑ‚Ğ¾ Ğ´Ğ¾Ğ»Ğ³Ğ¾ÑÑ€Ğ¾Ñ‡Ğ½Ğ¾Ğµ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ Ğ³Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ğ¾Ğ³Ğ¾Ğ´Ğ½Ñ‹Ñ… ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ğ¹ Ğ¸ Ñ‚ĞµĞ¼Ğ¿ĞµÑ€Ğ°Ñ‚ÑƒÑ€.",
        "ĞšĞ°ĞºĞ¾Ğ²Ñ‹ Ğ½Ğ°Ğ¸Ğ±Ğ¾Ğ»ĞµĞµ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸ ÑĞ¼ÑĞ³Ñ‡ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾ÑĞ»ĞµĞ´ÑÑ‚Ğ²Ğ¸Ğ¹ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ ĞºĞ»Ğ¸Ğ¼Ğ°Ñ‚Ğ° Ğ² Ğ¿Ñ€Ğ¸Ğ±Ñ€ĞµĞ¶Ğ½Ñ‹Ñ… ÑĞ¾Ğ¾Ğ±Ñ‰ĞµÑÑ‚Ğ²Ğ°Ñ…?",
        "Ğ’Ğ¾Ğ·Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼Ñ‹Ğµ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¸ ÑĞ½ĞµÑ€Ğ³Ğ¸Ğ¸, Ñ‚Ğ°ĞºĞ¸Ğµ ĞºĞ°Ğº ÑĞ¾Ğ»Ğ½ĞµÑ‡Ğ½Ğ°Ñ Ğ¸ Ğ²ĞµÑ‚Ñ€Ğ¾Ğ²Ğ°Ñ ÑĞ½ĞµÑ€Ğ³Ğ¸Ñ, Ğ¸Ğ¼ĞµÑÑ‚ Ñ€ĞµÑˆĞ°ÑÑ‰ĞµĞµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ ÑĞ¾ĞºÑ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ Ğ²Ñ‹Ğ±Ñ€Ğ¾ÑĞ¾Ğ² ÑƒĞ³Ğ»ĞµÑ€Ğ¾Ğ´Ğ°.",
        "Ğ¡ĞµĞ»ÑŒÑĞºĞ¾Ñ…Ğ¾Ğ·ÑĞ¹ÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğ¹ ÑĞµĞºÑ‚Ğ¾Ñ€ Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒÑÑ Ğº Ğ¸Ğ·Ğ¼ĞµĞ½ÑÑÑ‰Ğ¸Ğ¼ÑÑ ĞºĞ»Ğ¸Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ ÑƒÑĞ»Ğ¾Ğ²Ğ¸ÑĞ¼ Ğ´Ğ»Ñ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ²Ğ¾Ğ»ÑŒÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸.",
        "ĞœĞµĞ¶Ğ´ÑƒĞ½Ğ°Ñ€Ğ¾Ğ´Ğ½Ğ¾Ğµ ÑĞ¾Ñ‚Ñ€ÑƒĞ´Ğ½Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ Ğ´Ğ»Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ğ³Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ ĞºĞ»Ğ¸Ğ¼Ğ°Ñ‚Ğ°."
    ],
    "ja": [
        "æ°—å€™å¤‰å‹•ã¨ã¯ã€åœ°çƒè¦æ¨¡ã®æ°—è±¡ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨æ°—æ¸©ã®é•·æœŸçš„ãªå¤‰åŒ–ã§ã™ã€‚",
        "æ²¿å²¸åœ°åŸŸç¤¾ä¼šã«ãŠã‘ã‚‹æ°—å€™å¤‰å‹•ã®å½±éŸ¿ã‚’ç·©å’Œã™ã‚‹ãŸã‚ã®æœ€ã‚‚åŠ¹æœçš„ãªæˆ¦ç•¥ã¯ä½•ã§ã™ã‹ï¼Ÿ",
        "å¤ªé™½å…‰ã‚„é¢¨åŠ›ãªã©ã®å†ç”Ÿå¯èƒ½ã‚¨ãƒãƒ«ã‚®ãƒ¼æºã¯ã€ç‚­ç´ æ’å‡ºé‡ã‚’å‰Šæ¸›ã™ã‚‹ãŸã‚ã«ä¸å¯æ¬ ã§ã™ã€‚",
        "é£Ÿæ–™å®‰å…¨ä¿éšœã‚’ç¢ºä¿ã™ã‚‹ãŸã‚ã«ã¯ã€è¾²æ¥­éƒ¨é–€ã¯å¤‰åŒ–ã™ã‚‹æ°—å€™æ¡ä»¶ã«é©å¿œã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚",
        "æ°—å€™å¤‰å‹•ã¨ã„ã†ä¸–ç•Œçš„ãªèª²é¡Œã«å–ã‚Šçµ„ã‚€ãŸã‚ã«ã¯ã€å›½éš›å”åŠ›ãŒä¸å¯æ¬ ã§ã™ã€‚"
    ],
    "hi": [
        "à¤œà¤²à¤µà¤¾à¤¯à¥ à¤ªà¤°à¤¿à¤µà¤°à¥à¤¤à¤¨ à¤µà¥ˆà¤¶à¥à¤µà¤¿à¤• à¤®à¥Œà¤¸à¤® à¤ªà¥ˆà¤Ÿà¤°à¥à¤¨ à¤”à¤° à¤¤à¤¾à¤ªà¤®à¤¾à¤¨ à¤®à¥‡à¤‚ à¤à¤• à¤¦à¥€à¤°à¥à¤˜à¤•à¤¾à¤²à¤¿à¤• à¤¬à¤¦à¤²à¤¾à¤µ à¤¹à¥ˆà¥¤",
        "à¤¤à¤Ÿà¥€à¤¯ à¤¸à¤®à¥à¤¦à¤¾à¤¯à¥‹à¤‚ à¤®à¥‡à¤‚ à¤œà¤²à¤µà¤¾à¤¯à¥ à¤ªà¤°à¤¿à¤µà¤°à¥à¤¤à¤¨ à¤•à¥‡ à¤ªà¥à¤°à¤­à¤¾à¤µà¥‹à¤‚ à¤•à¥‹ à¤•à¤® à¤•à¤°à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤¸à¤¬à¤¸à¥‡ à¤ªà¥à¤°à¤­à¤¾à¤µà¥€ à¤°à¤£à¤¨à¥€à¤¤à¤¿à¤¯à¤¾à¤ à¤•à¥à¤¯à¤¾ à¤¹à¥ˆà¤‚?",
        "à¤¸à¥Œà¤° à¤”à¤° à¤ªà¤µà¤¨ à¤Šà¤°à¥à¤œà¤¾ à¤œà¥ˆà¤¸à¥‡ à¤¨à¤µà¥€à¤•à¤°à¤£à¥€à¤¯ à¤Šà¤°à¥à¤œà¤¾ à¤¸à¥à¤°à¥‹à¤¤ à¤•à¤¾à¤°à¥à¤¬à¤¨ à¤‰à¤¤à¥à¤¸à¤°à¥à¤œà¤¨ à¤•à¥‹ à¤•à¤® à¤•à¤°à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤®à¤¹à¤¤à¥à¤µà¤ªà¥‚à¤°à¥à¤£ à¤¹à¥ˆà¤‚à¥¤",
        "à¤–à¤¾à¤¦à¥à¤¯ à¤¸à¥à¤°à¤•à¥à¤·à¤¾ à¤¸à¥à¤¨à¤¿à¤¶à¥à¤šà¤¿à¤¤ à¤•à¤°à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤•à¥ƒà¤·à¤¿ à¤•à¥à¤·à¥‡à¤¤à¥à¤° à¤•à¥‹ à¤¬à¤¦à¤²à¤¤à¥€ à¤œà¤²à¤µà¤¾à¤¯à¥ à¤ªà¤°à¤¿à¤¸à¥à¤¥à¤¿à¤¤à¤¿à¤¯à¥‹à¤‚ à¤•à¥‡ à¤…à¤¨à¥à¤•à¥‚à¤² à¤¹à¥‹à¤¨à¤¾ à¤šà¤¾à¤¹à¤¿à¤à¥¤",
        "à¤œà¤²à¤µà¤¾à¤¯à¥ à¤ªà¤°à¤¿à¤µà¤°à¥à¤¤à¤¨ à¤•à¥€ à¤µà¥ˆà¤¶à¥à¤µà¤¿à¤• à¤šà¥à¤¨à¥Œà¤¤à¥€ à¤¸à¥‡ à¤¨à¤¿à¤ªà¤Ÿà¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤…à¤‚à¤¤à¤°à¥à¤°à¤¾à¤·à¥à¤Ÿà¥à¤°à¥€à¤¯ à¤¸à¤¹à¤¯à¥‹à¤— à¤†à¤µà¤¶à¥à¤¯à¤• à¤¹à¥ˆà¥¤"
    ],
    "de": [
        "Der Klimawandel ist eine langfristige VerÃ¤nderung der globalen Wettermuster und Temperaturen.",
        "Was sind die wirksamsten Strategien zur Minderung der Auswirkungen des Klimawandels in KÃ¼stengemeinden?",
        "Erneuerbare Energiequellen wie Sonnen- und Windenergie sind entscheidend fÃ¼r die Reduzierung der Kohlenstoffemissionen.",
        "Der Agrarsektor muss sich an die verÃ¤nderten klimatischen Bedingungen anpassen, um die ErnÃ¤hrungssicherheit zu gewÃ¤hrleisten.",
        "Internationale Zusammenarbeit ist unerlÃ¤sslich, um die globale Herausforderung des Klimawandels zu bewÃ¤ltigen."
    ],
    "fr": [
        "Le changement climatique est une modification Ã  long terme des rÃ©gimes mÃ©tÃ©orologiques et des tempÃ©ratures mondiales.",
        "Quelles sont les stratÃ©gies les plus efficaces pour attÃ©nuer les impacts du changement climatique dans les communautÃ©s cÃ´tiÃ¨res ?",
        "Les sources d'Ã©nergie renouvelables, telles que l'Ã©nergie solaire et Ã©olienne, sont cruciales pour rÃ©duire les Ã©missions de carbone.",
        "Le secteur agricole doit s'adapter aux conditions climatiques changeantes pour assurer la sÃ©curitÃ© alimentaire.",
        "La coopÃ©ration internationale est essentielle pour relever le dÃ©fi mondial du changement climatique."
    ],
    "es": [
        "El cambio climÃ¡tico es una alteraciÃ³n a largo plazo de los patrones meteorolÃ³gicos y las temperaturas globales.",
        "Â¿CuÃ¡les son las estrategias mÃ¡s eficaces para mitigar los impactos del cambio climÃ¡tico en las comunidades costeras?",
        "Las fuentes de energÃ­a renovables, como la solar y la eÃ³lica, son cruciales para reducir las emisiones de carbono.",
        "El sector agrÃ­cola debe adaptarse a las condiciones climÃ¡ticas cambiantes para garantizar la seguridad alimentaria.",
        "La cooperaciÃ³n internacional es esencial para abordar el desafÃ­o global del cambio climÃ¡tico."
    ],
    "tl": [
        "Ang pagbabago ng klima ay isang pangmatagalang pagbabago sa mga pattern ng panahon at temperatura sa buong mundo.",
        "Ano ang mga pinaka-epektibong estratehiya para sa pagpapagaan ng mga epekto ng pagbabago ng klima sa mga komunidad sa baybayin?",
        "Ang mga renewable na pinagkukunan ng enerhiya, tulad ng solar at wind power, ay mahalaga para sa pagbawas ng carbon emissions.",
        "Ang sektor ng agrikultura ay dapat mag-adapt sa mga nagbabagong kondisyon ng klima upang matiyak ang seguridad sa pagkain.",
        "Ang internasyonal na kooperasyon ay mahalaga para sa pagharap sa pandaigdigang hamon ng pagbabago ng klima."
    ]
}

# Cache configuration
CACHE_FILE = 'translation_cache.json'

# Initialize the Boto3 client for Bedrock Runtime
try:
    bedrock_client = boto3.client('bedrock-runtime')
except Exception as e:
    print(f"Error creating Boto3 client: {e}")
    print("Please ensure your AWS credentials and region are configured correctly.")
    exit()

def load_cache():
    """Load cached translations if available."""
    if os.path.exists(CACHE_FILE):
        with open(CACHE_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}

def save_cache(cache):
    """Save cache to file."""
    with open(CACHE_FILE, 'w', encoding='utf-8') as f:
        json.dump(cache, f, ensure_ascii=False, indent=4)

def estimate_tokens(text):
    """Rough estimation of tokens (4 chars per token approximation)."""
    return len(text) / 4

def calculate_cost(model_id, input_text, output_text):
    """Calculate estimated cost based on token usage."""
    if model_id not in MODEL_COSTS:
        return 0
    
    input_tokens = estimate_tokens(input_text) / 1000  # Convert to K tokens
    output_tokens = estimate_tokens(output_text) / 1000  # Convert to K tokens
    
    cost = (input_tokens * MODEL_COSTS[model_id]["input"] + 
            output_tokens * MODEL_COSTS[model_id]["output"])
    
    return cost

def translate_text(model_name, model_id, text, target_lang_name, cache):
    """
    Translates text using a specified Bedrock model via Boto3,
    with retries for throttling and graceful failure for access errors.
    """
    # Check cache first
    cache_key = f"{model_id}_{target_lang_name}_{text}"
    if cache_key in cache:
        cached_result = cache[cache_key]
        return cached_result['translation'], cached_result['response_time'], True
    
    prompt = f"""
    You are a professional translator.
    Translate the following English text to {target_lang_name}.
    Style: Formal
    Tone: Informative
    Glossary:
        - "Climate change" should be translated consistently.
        - "Carbon emissions" should be translated consistently.

    English text to translate: "{text}"
    Translation:
    """
    request_body = {
        "inputText": prompt,
        "textGenerationConfig": {
            "maxTokenCount": 1024,
            "temperature": 0.1,
            "topP": 0.9,
            "stopSequences": []
        }
    }

    max_retries = 3
    start_time = time.time()
    
    for attempt in range(max_retries):
        try:
            response = bedrock_client.invoke_model(
                modelId=model_id,
                contentType='application/json',
                accept='application/json',
                body=json.dumps(request_body)
            )
            response_body = json.loads(response['body'].read())
            translation = response_body['results'][0]['outputText'].strip()
            response_time = time.time() - start_time
            
            # Cache the result
            cache[cache_key] = {
                'translation': translation,
                'response_time': response_time
            }
            
            return translation, response_time, False
        except ClientError as e:
            error_code = e.response['Error']['Code']
            if error_code == 'ThrottlingException':
                print(f"  ...Rate limit hit for {model_name}. Retrying in {2**attempt}s...")
                time.sleep(2**attempt)
                continue
            elif error_code in ['AccessDeniedException', 'ValidationException']:
                print(f"  ...SKIPPING {model_name} ({model_id}). Reason: {error_code}.")
                return None, 0, False
            else:
                print(f"  ...An unhandled error occurred for {model_name}: {e}")
                return None, 0, False
    print(f"  ...Failed to get a response from {model_name} after {max_retries} retries.")
    return None, 0, False

```python
def create_visualizations(results_df):
    """Create charts and visualizations for the report."""
    # Set style
    plt.style.use('seaborn-v0_8-darkgrid')
    
    # 1. Quality Scores Heatmap
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))
    
    # BLEU scores heatmap
    bleu_pivot = results_df.pivot_table(values='BLEU', index='Model', columns='Language', aggfunc='mean')
    sns.heatmap(bleu_pivot, annot=True, fmt='.3f', cmap='YlGnBu', ax=ax1, vmin=0, vmax=1)
    ax1.set_title('BLEU Scores by Model and Language', fontsize=16, fontweight='bold')
    ax1.set_xlabel('')
    
    # chrF scores heatmap
    chrf_pivot = results_df.pivot_table(values='chrF', index='Model', columns='Language', aggfunc='mean')
    sns.heatmap(chrf_pivot, annot=True, fmt='.3f', cmap='YlOrRd', ax=ax2, vmin=0, vmax=100)
    ax2.set_title('chrF Scores by Model and Language', fontsize=16, fontweight='bold')
    
    plt.tight_layout()
    plt.savefig('quality_heatmaps.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    # 2. Performance Metrics
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
    
    # Average response time by model
    avg_response_time = results_df.groupby('Model')['Response_Time_Seconds'].mean().sort_values()
    avg_response_time.plot(kind='barh', ax=ax1, color='skyblue')
    ax1.set_title('Average Response Time by Model', fontsize=14, fontweight='bold')
    ax1.set_xlabel('Response Time (seconds)')
    
    # Total cost by model
    total_cost = results_df.groupby('Model')['Estimated_Cost'].sum().sort_values()
    total_cost.plot(kind='barh', ax=ax2, color='lightcoral')
    ax2.set_title('Total Cost by Model', fontsize=14, fontweight='bold')
    ax2.set_xlabel('Cost (USD)')
    
    # Quality vs Speed scatter
    model_summary = results_df.groupby('Model').agg({
        'BLEU': 'mean',
        'chrF': 'mean',
        'Response_Time_Seconds': 'mean'
    })
    model_summary['Combined_Quality'] = (model_summary['BLEU'] + model_summary['chrF']/100) / 2
    
    ax3.scatter(model_summary['Response_Time_Seconds'], model_summary['Combined_Quality'], s=200)
    for idx, row in model_summary.iterrows():
        ax3.annotate(idx, (row['Response_Time_Seconds'], row['Combined_Quality']), 
                    ha='center', va='bottom', fontsize=10)
    ax3.set_xlabel('Average Response Time (seconds)')
    ax3.set_ylabel('Combined Quality Score')
    ax3.set_title('Quality vs Speed Trade-off', fontsize=14, fontweight='bold')
    
    # Cost vs Quality scatter
    model_cost_quality = results_df.groupby('Model').agg({
        'Combined_Score': 'mean',
        'Estimated_Cost': 'sum'
    })
    
    ax4.scatter(model_cost_quality['Estimated_Cost'], model_cost_quality['Combined_Score'], s=200, color='green')
    for idx, row in model_cost_quality.iterrows():
        ax4.annotate(idx, (row['Estimated_Cost'], row['Combined_Score']), 
                    ha='center', va='bottom', fontsize=10)
    ax4.set_xlabel('Total Cost (USD)')
    ax4.set_ylabel('Average Combined Score')
    ax4.set_title('Cost vs Quality Trade-off', fontsize=14, fontweight='bold')
    
    plt.tight_layout()
    plt.savefig('performance_metrics.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    # 3. Language-specific performance
    fig, ax = plt.subplots(figsize=(12, 6))
    
    lang_perf = results_df.groupby(['Language', 'Model'])['Combined_Score'].mean().unstack()
    lang_perf.plot(kind='bar', ax=ax, width=0.8)
    ax.set_title('Model Performance by Language', fontsize=16, fontweight='bold')
    ax.set_xlabel('Language')
    ax.set_ylabel('Combined Score')
    ax.legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.xticks(rotation=45, ha='right')
    
    plt.tight_layout()
    plt.savefig('language_performance.png', dpi=300, bbox_inches='tight')
    plt.close()

def generate_report(results_df, timestamp):
    """Generate a comprehensive markdown report."""
    
    # Calculate summary statistics
    model_summary = results_df.groupby('Model').agg({
        'BLEU': ['mean', 'std'],
        'chrF': ['mean', 'std'],
        'Response_Time_Seconds': ['mean', 'std'],
        'Estimated_Cost': 'sum',
        'From_Cache': 'sum'
    }).round(3)
    
    # Calculate combined scores and rankings
    model_scores = results_df.groupby('Model').agg({
        'BLEU': 'mean',
        'chrF': 'mean',
        'Response_Time_Seconds': 'mean',
        'Estimated_Cost': 'sum'
    })
    
    # Normalize scores for fair comparison
    model_scores['Quality_Score'] = (model_scores['BLEU'] + model_scores['chrF']/100) / 2
    model_scores['Speed_Score'] = 1 / (1 + model_scores['Response_Time_Seconds'])
    model_scores['Cost_Efficiency'] = model_scores['Quality_Score'] / (model_scores['Estimated_Cost'] + 0.0001)
    model_scores['Overall_Score'] = (model_scores['Quality_Score'] * 0.5 + 
                                     model_scores['Speed_Score'] * 0.3 + 
                                     model_scores['Cost_Efficiency'] * 0.2)
    
    winner = model_scores['Overall_Score'].idxmax()
    
    report = f"""# AWS Bedrock Translation Model Bake-off Report

**Generated:** {timestamp}

## Executive Summary

We evaluated {len(MODELS_TO_TEST)} AWS Bedrock models across {len(LANGUAGES)} languages using {len(TEST_PHRASES)} test phrases for multilingual translation capabilities. The evaluation focused on translation quality, response time, and cost efficiency.

### ğŸ† Overall Winner: **{winner}**

Based on a weighted score combining:
- Translation Quality (50%)
- Response Speed (30%)  
- Cost Efficiency (20%)

## Models Tested
"""
    
    for model_name, model_id in MODELS_TO_TEST.items():
        report += f"- **{model_name}**: `{model_id}`\n"
    
    report += f"""
## Languages Evaluated
{', '.join(LANGUAGES.keys())}

## Key Findings

### 1. Quality Metrics (BLEU & chrF)
"""
    
    # Add quality rankings
    quality_rankings = model_scores.sort_values('Quality_Score', ascending=False)
    for idx, (model, row) in enumerate(quality_rankings.iterrows(), 1):
        report += f"{idx}. **{model}**: {row['Quality_Score']:.3f} (BLEU: {row['BLEU']:.3f}, chrF: {row['chrF']:.1f})\n"
    
    report += """
### 2. Performance Metrics
"""
    
    # Add performance rankings
    speed_rankings = model_scores.sort_values('Response_Time_Seconds')
    for idx, (model, row) in enumerate(speed_rankings.iterrows(), 1):
        report += f"{idx}. **{model}**: {row['Response_Time_Seconds']:.2f}s average response time\n"
    
    report += """
### 3. Cost Analysis
"""
    
    # Add cost rankings
    cost_rankings = model_scores.sort_values('Estimated_Cost')
    for idx, (model, row) in enumerate(cost_rankings.iterrows(), 1):
        report += f"{idx}. **{model}**: ${row['Estimated_Cost']:.4f} total cost\n"
    
    report += f"""
## Detailed Results

### Model Performance Summary

| Model | Avg BLEU | Avg chrF | Avg Response Time (s) | Total Cost ($) | Cache Hits |
|-------|----------|----------|----------------------|----------------|------------|
"""
    
    for model in model_summary.index:
        row = model_summary.loc[model]
        report += f"| {model} | {row['BLEU']['mean']:.3f} Â± {row['BLEU']['std']:.3f} | "
        report += f"{row['chrF']['mean']:.1f} Â± {row['chrF']['std']:.1f} | "
        report += f"{row['Response_Time_Seconds']['mean']:.2f} Â± {row['Response_Time_Seconds']['std']:.2f} | "
        report += f"{row['Estimated_Cost']['sum']:.4f} | {int(row['From_Cache']['sum'])} |\n"
    
    # Language-specific insights
    report += """
### Language-Specific Performance

"""
    
    lang_performance = results_df.groupby(['Language', 'Model'])['Combined_Score'].mean().unstack()
    best_model_per_lang = lang_performance.idxmax(axis=1)
    
    report += "| Language | Best Performing Model | Score |\n"
    report += "|----------|----------------------|-------|\n"
    for lang, model in best_model_per_lang.items():
        score = lang_performance.loc[lang, model]
        report += f"| {lang} | {model} | {score:.3f} |\n"
    
    # Add recommendations
    report += f"""
## Recommendations

### For High-Quality Requirements
**Recommended:** {quality_rankings.index[0]}
- Best overall translation quality
- Consistent performance across languages

### For Real-Time Applications
**Recommended:** {speed_rankings.index[0]}
- Fastest response times
- Suitable for interactive applications

### For Budget-Conscious Deployments
**Recommended:** {cost_rankings.index[0]}
- Most cost-effective option
- Good quality-to-cost ratio

### Balanced Choice
**Recommended:** {winner}
- Best overall combination of quality, speed, and cost
- Suitable for most use cases

## Technical Notes

- **Caching**: Results were cached to reduce API calls and costs on repeated runs
- **Token Estimation**: Based on 4 characters per token approximation
- **Cost Calculation**: Using AWS Bedrock pricing as of the test date
- **Quality Metrics**: 
  - BLEU: Measures n-gram precision
  - chrF: Character-level F-score, better for morphologically rich languages

## Visualizations

See the following generated charts:
- `quality_heatmaps.png`: BLEU and chrF scores by model and language
- `performance_metrics.png`: Response time, cost, and trade-off analyses
- `language_performance.png`: Model performance breakdown by language
"""
    
    return report

def main():
    """
    Main function to run the translation bake-off.
    """
    print("ğŸš€ Starting AWS Bedrock Translation Model Bake-off\n")
    
    results = []
    bleu = evaluate.load('bleu')
    chrf = evaluate.load('chrf')
    
    # Load cache
    cache = load_cache()
    initial_cache_size = len(cache)
    
    # Keep track of models that have already failed to avoid re-printing skip messages
    skipped_models = set()
    
    # Calculate total operations for progress bar
    total_operations = sum